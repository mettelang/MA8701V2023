@Manual{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2013},
    url = {http://www.R-project.org/},
  }

@Article{mice,
    title = {{mice}: Multivariate Imputation by Chained Equations in
      R},
    author = {Stef {van Buuren} and Karin Groothuis-Oudshoorn},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {45},
    number = {3},
    pages = {1-67},
    doi = {10.18637/jss.v045.i03},
  }
 @article{lydersen_multippel,
	title = {Multippel imputering av manglende data},
	issn = {0029-2001},
	doi = {10.4045/tidsskr.21.0772},
	journal = {Tidsskrift for Den norske legeforening},
	author = {Lydersen, Stian},
	year = {2022},
}

  @Book{mass,
    title = {Modern Applied Statistics with S},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0},
    url = {https://www.stats.ox.ac.uk/pub/MASS4/},
  }

 @Article{precrec,
    title = {Precrec: fast and accurate precision-recall and ROC curve
      calculations in R},
    author = {Takaya Saito and Marc Rehmsmeier},
    journal = {Bioinformatics},
    year = {2017},
    volume = {33 (1)},
    pages = {145-147},
    doi = {10.1093/bioinformatics/btw570},
  }

@book{VanBuuren2018,
 address = {Boca Raton, FL.},
 author = {{van Buuren}, Stef},
 publisher = {CRC Press},
 title = {Flexible Imputation of Missing Data. Second Edition.},
 year = {2018},
}


PHDThesis{brandphd,
 title                = {Development, Implementation and Evaluation of Multiple Imputation Strategies for the Statistical Analysis of Incomplete Data Sets},
 author               = {Brand, Jaap},
 school               = {E},
 year                 = 1999,
 month                = apr,
 url                  = {http://hdl.handle.net/1765/19790}
}

@misc{WNvW,
author = "Wessel N. van Wieringen",
year = "2020",
title = "Lecture notes on ridge regression",
url = "https://arxiv.org/pdf/1509.09169.pdf"
}

@misc{Dua:2017 ,
author = "Dheeru, Dua and Karra Taniskidou, Efi",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@book{ISL,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume={112},
  year={2013},
  publisher={Springer}
}

@book{ESL,
  title={The elements of statistical learning: Data Mining, Inference, and Prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  volume={2},
  year={2009},
  publisher={Springer series in statistics New York},
  url={hastie.su.domains/ElemStatLearn}
}

@article{Bagging,
author={Leo Breiman},
title={Bagging Predictors},
journal={Machine Learning},
volume={24},
pages={123-140},
year={1996}}

@article{RandomForest,
author={Leo Breiman},
title={Random Forest},
journal={Machine Learning},
volume={45},
pages={5-32},
year={2001}}

@article{SVMinR,
author={A. Karatzoglou and D. Meyer and K. Hornik},
title={Support Vector Machines in R},
journal={Journal of Statistical Software},
volume={15},
number={9},
year={2006}}

@book{Ripley,
title={Pattern Recognicion and Neural Networks},
author={Brian D. Ripley},
year={1996},
publisher={Cambridge University Press}}

@book{casi,
title={Computer age statistical inference - algorithms, evidence, and data science},
author={Bradley Efron and Trevor Hastie},
year={2016},
url={https://hastie.su.domains/CASI/},
publisher={Cambridge University Press}}

@book{MASS,
title={Modern Applied Statistics with S},
author={W. N. Venables and B. D. Ripley},
year={2002},
publisher={Springer}
}

@book{goodfellow,
title={Deep learning},
author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
year={2016},
publisher={MIT Press}}

@book{kerasR,
title={Deep learning with R},
author={François Chollet and J. J. Allaire},
year={2018},
publisher={Manning Press}}

@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@article{aleplot2020,
author = {Apley, Daniel W. and Zhu, Jingyu},
title = {Visualizing the effects of predictor variables in black box supervised learning models},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {82},
number = {4},
pages = {1059-1086},
keywords = {Functional analysis of variance, Marginal plots, Partial dependence plots, Supervised learning, Visualization},
doi = {https://doi.org/10.1111/rssb.12377},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12377},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12377},
abstract = {Summary In many supervised learning applications, understanding and visualizing the effects of the predictor variables on the predicted response is of paramount importance. A shortcoming of black box supervised learning models (e.g. complex trees, neural networks, boosted trees, random forests, nearest neighbours, local kernel-weighted methods and support vector regression) in this regard is their lack of interpretability or transparency. Partial dependence plots, which are the most popular approach for visualizing the effects of the predictors with black box supervised learning models, can produce erroneous results if the predictors are strongly correlated, because they require extrapolation of the response at predictor values that are far outside the multivariate envelope of the training data. As an alternative to partial dependence plots, we present a new visualization approach that we term accumulated local effects plots, which do not require this unreliable extrapolation with correlated predictors. Moreover, accumulated local effects plots are far less computationally expensive than partial dependence plots. We also provide an R package ALEPlot as supplementary material to implement our proposed method.},
year = {2020}
}

@InProceedings{Dandletal2020,
author="Dandl, Susanne
and Molnar, Christoph
and Binder, Martin
and Bischl, Bernd",
editor="B{\"a}ck, Thomas
and Preuss, Mike
and Deutz, Andr{\'e}
and Wang, Hao
and Doerr, Carola
and Emmerich, Michael
and Trautmann, Heike",
title="Multi-Objective Counterfactual Explanations",
booktitle="Parallel Problem Solving from Nature -- PPSN XVI",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="448--469",
url={https://link.springer.com/content/pdf/10.1007%2F978-3-030-58112-1_31.pdf},
abstract="Counterfactual explanations are one of the most popular methods to make predictions of black box machine learning models interpretable by providing explanations in the form of `what-if scenarios'. Most current approaches optimize a collapsed, weighted sum of multiple objectives, which are naturally difficult to balance a-priori. We propose the Multi-Objective Counterfactuals (MOC) method, which translates the counterfactual search into a multi-objective optimization problem. Our approach not only returns a diverse set of counterfactuals with different trade-offs between the proposed objectives, but also maintains diversity in feature space. This enables a more detailed post-hoc analysis to facilitate better understanding and also more options for actionable user responses to change the predicted outcome. Our approach is also model-agnostic and works for numerical and categorical input features. We show the usefulness of MOC in concrete cases and compare our approach with state-of-the-art methods for counterfactual explanations.",
isbn="978-3-030-58112-1"
}

@article{gromping2007,
author = {Grömping, U.},
title = {Estimators of Relative Importance in Linear Regression Based on Variance Decomposition},
journal = {The American Statistician},
volume = {61},
year=2007,
pages = {139-147},
eprint = {https://prof.beuth-hochschule.de/fileadmin/prof/groemp/downloads/amstat07mayp139.pdf}}


@Article{ice2015,
    title = {Peeking Inside the Black Box: Visualizing Statistical
      Learning With Plots of Individual Conditional Expectation},
    author = {Alex Goldstein and Adam Kapelner and Justin Bleich and
      Emil Pitkin},
    journal = {Journal of Computational and Graphical Statistics},
    volume = {24},
    number = {1},
    pages = {44--65},
    doi = {10.1080/10618600.2014.907095},
    year = {2015},
  }

@inproceedings{LundbergLee2017,
 author = {Lundberg, Scott M and Lee, Su-In},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf},
 volume = {30},
 year = {2017}
}

@Article{Wachter2018,
title={Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR},
author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
journal={Harvard Journal of Law \& Technology},
volume=31,
number=2,
year=2018,
url={http://dx.doi.org/10.2139/ssrn.3063289}} 

@inproceedings{lime2016,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {explaining machine learning, interpretable machine learning, interpretability, black box classifier},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@Article{Aas2021,
title={Explaining individual predictions when features are dependent: More accurate approximations to Shapley values},
author={Kjersti Aas and Martin Jullum and Anders Løland},
journal={Artificial Intelligence},
year=2021,
url={https://doi.org/10.1016/j.artint.2021.103502}} 

@Article{Johnson2000,
title= {Heuristic Method for Estimating the Relative Weight of Predictor Variables in Multiple Regression},
author={Johnson, J W.},
journal={Multivariate behavioral research},
year={2000},
url={doi:10.1207/S15327906MBR3501_1}}

@article{taylor2015,
	title = {Statistical learning and selective inference},
	volume = {112},
	issn = {1091-6490},
	doi = {10.1073/pnas.1507583112},
	abstract = {We describe the problem of "selective inference." This addresses the following challenge: Having mined a set of data to find potential associations, how do we properly assess the strength of these associations? The fact that we have "cherry-picked"--searched for the strongest associations--means that we must set a higher bar for declaring significant the associations that we see. This challenge becomes more important in the era of big data and complex statistical modeling. The cherry tree (dataset) can be very large and the tools for cherry picking (statistical learning methods) are now very sophisticated. We describe some recent new developments in selective inference and illustrate their use in forward stepwise regression, the lasso, and principal components analysis.},
	language = {eng},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Taylor, Jonathan and Tibshirani, Robert J.},
	month = jun,
	year = {2015},
	pmid = {26100887},
	pmcid = {PMC4485109},
	keywords = {Datasets as Topic, Learning, Models, Statistical, P values, inference, lasso},
	pages = {7629--7634},
}

@book{missinghandbook2014,
	address = {Boca Raton},
	series = {Chapman \& {Hall}/{CRC} {Handbooks} of {Modern} {Statistical} {Methods}},
	title = {Handbook of {Missing} {Data} {Methodology}},
	isbn = {978-1-4398-5461-7},
	url = {https://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=1499432&site=ehost-live&scope=site},
	abstract = {Missing data affect nearly every discipline by complicating the statistical analysis of collected data. But since the 1990s, there have been important developments in the statistical methodology for handling missing data. Written by renowned statisticians in this area, Handbook of Missing Data Methodology presents many methodological advances and t},
	language = {English},
	urldate = {2022-11-05},
	publisher = {Chapman and Hall/CRC},
	author = {Molenberghs, Geert and Fitzmaurice, Garrett and Kenward, Michael G. and Tsiatis, Anastasios and Verbeke, Geert},
	year = {2014},
	keywords = {MATHEMATICS / Probability \& Statistics / General, Missing observations (Statistics), Statistics--Methodology},
}

@book{dunnsmythGLM,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {Generalized {Linear} {Models} {With} {Examples} in {R}},
	isbn = {978-1-4419-0117-0 978-1-4419-0118-7},
	url = {http://link.springer.com/10.1007/978-1-4419-0118-7},
	language = {en},
	urldate = {2022-11-22},
	publisher = {Springer New York},
	author = {Dunn, Peter K. and Smyth, Gordon K.},
	year = {2018},
	doi = {10.1007/978-1-4419-0118-7},
}



